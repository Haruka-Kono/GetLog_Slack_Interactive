{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb8bfa2-ce69-431d-b9e9-d4bd9833f487",
   "metadata": {},
   "source": [
    "# For Getting channels log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55f077-75fd-4c92-9192-f42ac0af5291",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c473438-f06a-4d49-a98b-c8a3d7f27690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from slack_sdk import WebClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "import openpyxl\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19b385-e518-47df-a22f-91f318600def",
   "metadata": {
    "tags": []
   },
   "source": [
    "## WebApp settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0c8db-64ea-4438-ade1-c6babef6f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = urllib.request.getproxies().get('http')\n",
    "print(proxy)\n",
    "client = WebClient(token=os.environ['TEST_CH_BOT_TOKEN'], proxy=proxy)\n",
    "uclient = WebClient(token=os.environ['TEST_CH_USER_TOKEN'], proxy=proxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6e3da-583a-40f6-8639-5695c396bde1",
   "metadata": {},
   "source": [
    "## get messages (without replies) in specified channel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828121c4-96ba-4279-9c68-54d5006d9442",
   "metadata": {},
   "source": [
    "### get channels (chs) ids and names in your workspace\n",
    "#### retrive wholl info of chs (for backup raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223bb19-6009-4894-be4d-64eb1a6b7b2a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ws_info = uclient.conversations_list()\n",
    "ws_info_ch = ws_info.get('channels')\n",
    "df_ch_info = pd.json_normalize(ws_info_ch)\n",
    "print(df_ch_info.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5532df8e-3f6f-4042-ac23-971e9c1eb8a6",
   "metadata": {},
   "source": [
    "#### extract chs ids and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3005a85-26cd-4495-b117-d1c98673d3da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ch_id_name = []\n",
    "for i in zip(df_ch_info['id'], df_ch_info['name']):\n",
    "    ch_id_name.append(i)\n",
    "\n",
    "df_ch_id_name = df_ch_info[['id', 'name']]\n",
    "df_ch_id_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f98da9-2256-4240-aaf6-6476a45ba202",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### specify channel for retriving log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f762367-eb2f-41f8-944a-d65732d3ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: specify a channel named 'devslacksdk'\n",
    "ch_idx = 1 # select number on the left of 'id' column above table\n",
    "\n",
    "ch_id = df_ch_id_name['id'][ch_idx]\n",
    "ch_name = df_ch_id_name['name'][ch_idx]\n",
    "print('Specified channel: '+ch_name+', ch_id: '+ch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c029968-3c31-4311-b41a-f81d79e8032d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get messages log for specified ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89125f79-fe2e-4ca2-8d34-fd741bbc22ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### retrive raw data and create table of messages log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b9cff2-770c-4b2c-aa4c-97fefabf310c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ch_log = uclient.conversations_history(channel=ch_id) # it is raw data without replies\n",
    "ch_ms_log = ch_log['messages']\n",
    "\n",
    "df_ch_ms_log = pd.json_normalize(ch_ms_log)\n",
    "list_log = []\n",
    "\n",
    "# slack API can retrive only 100 messages at once, so following steps are for retriving over 100.\n",
    "i = 0\n",
    "if ch_log['has_more'] == True:\n",
    "    while ch_log['has_more'] == True:\n",
    "        ch_log = uclient.conversations_history(channel=ch_id, cursor=ch_log['response_metadata']['next_cursor'])\n",
    "        ch_ms_log_n = ch_log['messages']\n",
    "        list_log.append(ch_log['messages'])\n",
    "        \n",
    "        df_ch_ms_log_n = pd.json_normalize(ch_ms_log_n)\n",
    "        df_ch_ms_log = df_ch_ms_log.append(df_ch_ms_log_n)\n",
    "        i += 1\n",
    "print(i)\n",
    "flat = [x for row in list_log for x in row]\n",
    "ch_ms_log.extend(flat) # ch_ms_log can be stored over 100 logs\n",
    "print(len(ch_ms_log)) # num of messages\n",
    "df_ch_ms_log.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248982a2-50ee-4e5a-b638-2d0096af90b6",
   "metadata": {},
   "source": [
    "#### select info what you want to retrive and format table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a2737-074f-4b0d-b2e0-90e05283d794",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reindex_col = ['type', 'thread_ts', 'ts', 'user', 'text', 'reply_count', 'reply_users_count', 'topic']\n",
    "df_ch_ms_log = df_ch_ms_log.reindex(columns=reindex_col)\n",
    "df_ch_ms_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915c93c-24d5-40a3-b470-d8826a22b6fb",
   "metadata": {},
   "source": [
    "### (in MESSAGES) retrive attached files and create table contains file name and download url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f6079-6236-448d-b891-72dd1395ce84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for i in df_ch_ms_log.index:\n",
    "    if 'files' in ch_ms_log[i].keys():\n",
    "        files.append(ch_ms_log[i]['files'][0])\n",
    "    else:\n",
    "        files.append({'name': 'None', 'url_private_download': 'None'})  \n",
    "\n",
    "df_ch_files_ms = pd.json_normalize(files)\n",
    "df_ch_files_ms = df_ch_files_ms[['name', 'url_private_download']]\n",
    "df_ch_files_ms = df_ch_files_ms.rename(columns={'name': 'FileName', 'url_private_download': 'FileURL'})\n",
    "df_ch_files_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d514a1-08c8-4cd6-b24f-47a26422d07e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### combine MESSAGE table with file rep table and sort by ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca84c53-007e-4ff1-b351-cbbb9c5f2761",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ch_ms_log = pd.concat([df_ch_ms_log, df_ch_files_ms], axis=1).sort_values('ts').reset_index().drop(columns='index')\n",
    "df_ch_ms_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84f991-be4e-4af9-83a2-9504c25afbbd",
   "metadata": {},
   "source": [
    "---\n",
    "## get replies to associate with each replies by parent messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1edee-fbad-46b7-bffa-ad6895402489",
   "metadata": {},
   "source": [
    "### search messages including replies and retrive reps with parent messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2de66b-edf4-484d-bc25-038fa776c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "for i in df_ch_ms_log.index:\n",
    "    if np.isnan(df_ch_ms_log['reply_count'][i]) == False:\n",
    "        thr = uclient.conversations_replies(channel=ch_id, ts=df_ch_ms_log['thread_ts'][i])\n",
    "        thr_ms = thr.get('messages')\n",
    "        threads.append(thr_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d5301-b8ee-465c-89b8-842ac1029dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reps = []\n",
    "for i in range(len(threads)):\n",
    "    rep = threads[i]\n",
    "    for j in range(len(rep)):\n",
    "        reps.append(rep[j])\n",
    "print(len(reps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa077a0-5596-4dfe-a220-8b95e50cbd90",
   "metadata": {},
   "source": [
    "### following steps for create table contains messages and reps\n",
    "#### create reply table\n",
    "#### (in REPLIES) retrive attached files and create table contains file name and download url\n",
    "#### combine REPLY table with FILE table and sort by timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5b3e3-a8a4-432d-9777-76e189c3eeba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(reps) != 0:\n",
    "    # create reply table\n",
    "    reindex_col = ['type', 'thread_ts', 'ts', 'user', 'text', 'reply_count', 'reply_users_count', 'topic']\n",
    "    df_ch_rep = pd.json_normalize(reps).reindex(columns=reindex_col)\n",
    "\n",
    "    \n",
    "    # (in REPLIES) retrive attached files and create table contains file name and download url\n",
    "    files_rep = []\n",
    "    for i in range(len(reps)):\n",
    "        if 'files' in reps[i].keys():\n",
    "            files_rep.append(reps[i]['files'][0])\n",
    "        else:\n",
    "            files_rep.append({'name': 'None', 'url_private_download': 'None'})\n",
    "\n",
    "    df_files_rep = pd.json_normalize(files_rep)\n",
    "    df_files_rep = df_files_rep[['name', 'url_private_download']]\n",
    "    df_files_rep = df_files_rep.rename(columns={'name': 'FileName', 'url_private_download': 'FileURL'})\n",
    "    print(df_files_rep)\n",
    "\n",
    "    # combine REPLY table with FILE table and sort by thread_ts\n",
    "    df_ch_rep_log = pd.concat([df_ch_rep, df_files_rep], axis=1).sort_values('thread_ts').reset_index().drop(columns='index')\n",
    "    df_ch_rep_log['type']='thread'\n",
    "    print(df_ch_rep_log)\n",
    "\n",
    "    \n",
    "    # combine MESSAGE with REPLY \n",
    "    df_ch_log = pd.concat([df_ch_ms_log, df_ch_rep_log])\n",
    "    # remove duplicated parent messages by drop_duplicates\n",
    "    df_ch_log = df_ch_log.drop_duplicates(subset = ['text', 'ts'], keep='last').reset_index().drop(columns='index')\n",
    "\n",
    "\n",
    "else:\n",
    "    df_ch_log = df_ch_ms_log\n",
    "df_ch_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e647dc2-81ca-4d11-998c-cd14caacc099",
   "metadata": {},
   "source": [
    "## shape table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcaf47e-4a67-4a42-9c98-b4f7239a7785",
   "metadata": {},
   "source": [
    "### convert dtypes of ts and thread_ts, from str to float, and replace NaN to 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c57fc-4aa2-4a8f-8b3f-bb2306a57825",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ch_log_astype = df_ch_log.astype({'ts': float, 'thread_ts': float}).fillna('None')\n",
    "df_ch_log_astype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae225b-17bb-4f10-8424-33f408d4db13",
   "metadata": {},
   "source": [
    "### replace UNIX DATE to formatted one and separate ts to date and time (for multiindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc628d6e-3188-41d3-9166-b74fa9545ad5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "date = []\n",
    "time = []\n",
    "for i in df_ch_log_astype.index:\n",
    "    if (type(df_ch_log_astype['ts'][i]) == np.float64 or \n",
    "        type(df_ch_log_astype['ts'][i]) == float):\n",
    "        # create list of date\n",
    "        dt_raw = datetime.date.fromtimestamp(df_ch_log_astype['ts'][i])\n",
    "        dt = dt_raw.strftime('%a, %b %d, %Y')\n",
    "        date.append(dt)\n",
    "        print('finished formatting ts to date')        \n",
    "        \n",
    "        # create list of time\n",
    "        ti_raw = datetime.datetime.fromtimestamp(df_ch_log_astype['ts'][i])\n",
    "        ti = ti_raw.strftime('%H:%M')\n",
    "        time.append(ti)\n",
    "        print('finished formatting ts to time') \n",
    "    \n",
    "    # format thread_ts to datetime\n",
    "    if (type(df_ch_log_astype['thread_ts'][i]) == np.float64 or \n",
    "        type(df_ch_log_astype['thread_ts'][i]) == float):\n",
    "        dtime = datetime.datetime.fromtimestamp(df_ch_log_astype['thread_ts'][i])\n",
    "        df_ch_log_astype.iloc[i, 1] = dtime.strftime('%H:%M, %a, %b %d, %Y')\n",
    "        print ('finished formatting thread_ts')\n",
    "    \n",
    "    else:\n",
    "        print('thread_ts is not found')\n",
    "\n",
    "df_datetime = pd.DataFrame({'date': date, \n",
    "                            'time': time})\n",
    "df_ch_log_frt = pd.concat([df_datetime, df_ch_log_astype],axis=1).drop(columns='ts')\n",
    "df_ch_log_frt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bffecca-073c-4052-b0aa-526766949040",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get users info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03e0ae-1c6d-4194-9656-284837fdadf7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_info = uclient.users_list().get('members')\n",
    "df_users_info = pd.json_normalize(users_info)\n",
    "\n",
    "# create list of user_id and names\n",
    "user_id_names = []\n",
    "for i in zip(df_users_info['id'], df_users_info['real_name']):\n",
    "    user_id_names.append(i)\n",
    "df_user_id_names = pd.DataFrame(user_id_names,columns=['id', 'real_name']).fillna('deleted user').astype({'real_name': str})\n",
    "df_user_id_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4d5e0-5683-43c5-bfae-a952963dbf99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### replace user id in 'names' column to 'real_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d6e2b-9cd6-4861-a3d4-e3424b6d6dea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in df_ch_log_frt.index:\n",
    "    for j in range(len(user_id_names)):\n",
    "        if df_ch_log_frt.user[i] == df_user_id_names['id'][j]:\n",
    "            df_ch_log_frt.user[i] = df_user_id_names['real_name'][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676e276-bf4f-4620-89e8-f0021f443dee",
   "metadata": {},
   "source": [
    "### replace user id in 'text' column to 'real_name' (maybe able to merge above cell?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa2262-309f-4329-9921-aac8b7664942",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_ch_log_frt.index:\n",
    "    for j in df_user_id_names.index:\n",
    "        if df_user_id_names['id'][j] in df_ch_log_frt['text'][i]:\n",
    "            df_ch_log_frt['text'][i] = df_ch_log_frt['text'][i].replace(df_user_id_names['id'][j], df_user_id_names['real_name'][j])\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f4c71-a302-41a5-88aa-1e9b8bf11b34",
   "metadata": {},
   "source": [
    "### for only uploading file (None of text fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78bd740-9364-4da8-8305-78dc731105db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in df_ch_log_frt.index:\n",
    "    if df_ch_log_frt.text[i] == '':\n",
    "        df_ch_log_frt.text[i] = 'attached file(s) only'\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2debaee-fe9b-41c1-b04a-1e7010ef1787",
   "metadata": {},
   "source": [
    "### check result of formatting and replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038447e1-3d91-43c5-9801-eb95a574a4d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ch_log_frt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96582196-ce62-47ee-83ee-9e6678271e5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### multiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14586854-a858-4bc8-8a41-6dcc3648ba4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ch_log_frt_mi = df_ch_log_frt.set_index(['type', 'thread_ts', 'date', 'time'])\n",
    "df_ch_log_frt_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3108e76-4656-4127-960e-9dabefa594be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## export files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8e1ba-31e5-4bbd-ace5-03c9ac17340b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### setting *you can custom something (year, path, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190e1a0-f06d-4df5-a8fd-df1bdd1ed7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_date = datetime.date.today()\n",
    "backup_date = backup_date.strftime('%y%m%d')\n",
    "\n",
    "# DO NOT FORGET MODIFY YEAR (year of current backup workspace) \n",
    "tgt_ws_year = 2022\n",
    "print(backup_date)\n",
    "print(ch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf6293-7576-49e5-b93e-4b723cffaa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ch = '../channel/'\n",
    "if os.path.exists(path_ch) == False:\n",
    "    %mkdir path_ch\n",
    "else:\n",
    "    print('directory already exists')\n",
    "    \n",
    "path_ch_full = '../ch_full_log/'\n",
    "if os.path.exists(path_ch_full) == False:\n",
    "    %mkdir path_ch_full\n",
    "else:\n",
    "    print('directory already exists')\n",
    "    \n",
    "path_YEAR = str(tgt_ws_year)\n",
    "if os.path.exists(path_ch+path_YEAR) == False:\n",
    "    %mkdir path_ch+path_YEAR\n",
    "else:\n",
    "    print('directory already exists')\n",
    "\n",
    "if os.path.exists(path_ch_full+path_YEAR) == False:\n",
    "    %mkdir path_ch_full+path_YEAR\n",
    "else:\n",
    "    print('directory already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0db58-1ece-4e2d-bfa3-ef6749a072b0",
   "metadata": {},
   "source": [
    "### export excel file (for remaining multiIndex and encoding automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e98a7-eb27-402a-aa21-81d4585032b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch_log_frt_mi.to_excel(path_ch+path_YEAR+'/log_ch_'+path_YEAR+'_'+ch_name+'_'+backup_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df8247-e748-4d4c-a975-010bfd591dc2",
   "metadata": {},
   "source": [
    "### export raw file (json format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4672c5-fe58-4db5-ad78-7ef5baa71e28",
   "metadata": {},
   "source": [
    "#### not included replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb845cf1-8056-4d67-922a-45a778999829",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_ch_full+path_YEAR+'/Raw_ch_log_NOrep_'+path_YEAR+'_'+ch_name+'_'+backup_date+'.dat', 'w') as f:\n",
    "    print(ch_log, file=f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd85827-35b1-4acb-bb71-ac304953228e",
   "metadata": {},
   "source": [
    "#### replies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029281e-f438-4b16-a7d4-35291d36e910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(path_ch_full+path_YEAR+'/Raw_ch_rep_log_'+path_YEAR+'_'+ch_name+'_'+backup_date+'.dat', 'w') as f:\n",
    "    print(thr, file=f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
