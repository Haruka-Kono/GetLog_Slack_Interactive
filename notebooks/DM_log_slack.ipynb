{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c473438-f06a-4d49-a98b-c8a3d7f27690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "from slack_bolt import App\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import openpyxl\n",
    "import requests\n",
    "import json\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d337ee-bb42-4cf5-9710-bff7afa9ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0c8db-64ea-4438-ade1-c6babef6f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = urllib.request.getproxies().get('http')\n",
    "client = WebClient(token=os.environ['BOT_TOKEN_HK'], proxy=proxy) \n",
    "uclient = WebClient(token=os.environ['USER_TOKEN_HK'], proxy=proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03e0ae-1c6d-4194-9656-284837fdadf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get users data\n",
    "users_info = uclient.users_list().get('members')\n",
    "df_users_info = pd.json_normalize(users_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013922a-c7a6-4a1e-a4ce-700f38dce9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of user_id and names\n",
    "user_id_names = []\n",
    "for i in zip(df_users_info['id'], df_users_info['real_name']):\n",
    "    user_id_names.append(i)\n",
    "df_user_id_names = pd.DataFrame(user_id_names,columns=['id', 'real_name'])\n",
    "df_user_id_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5095e-7cef-4b38-ac29-4a2abab10efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify user whom you want to retrive logs of DM with\n",
    "usr_idx = 5\n",
    "dm_user_id = df_user_id_names['id'][usr_idx]\n",
    "dm_user_name = df_user_id_names['real_name'][usr_idx]\n",
    "dm_user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce944961-5b03-49ca-aefe-65a204cebd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DM channel raw data and id\n",
    "dm_info = uclient.conversations_open(users=dm_user_id)\n",
    "print(dm_info)\n",
    "dm = dm_info.get('channel')\n",
    "print(dm['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c476b2-e6bf-43b6-bd30-c83a8153fa9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get DM logs    \n",
    "log_dm = uclient.conversations_history(channel=dm['id'])\n",
    "log_dm_ms = log_dm['messages']\n",
    "list_log = []\n",
    "df_log_dm_ms = pd.json_normalize(log_dm_ms)\n",
    "i = 0\n",
    "\n",
    "# can get over 100 messages\n",
    "if log_dm['has_more'] == True:\n",
    "    while log_dm['has_more'] == True:\n",
    "        log_dm = uclient.conversations_history(channel=dm['id'], cursor=log_dm['response_metadata']['next_cursor'])\n",
    "        log_dm_ms_n = log_dm['messages']\n",
    "        list_log.append(log_dm['messages'])\n",
    "\n",
    "        df_log_dm_ms_n = pd.json_normalize(log_dm_ms_n)\n",
    "        df_log_dm_ms = df_log_dm_ms.append(df_log_dm_ms_n)\n",
    "        i += 1\n",
    "print(i)\n",
    "flat = [x for row in list_log for x in row]\n",
    "log_dm_ms.extend(flat)\n",
    "print(len(log_dm_ms))\n",
    "df_log_dm_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63cd1be-e3a3-4386-9d2f-20cd94feb204",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select columns to use\n",
    "reindex_col = ['type', 'ts', 'user', 'text', 'subtype', 'reply_count', 'reply_users_count', 'thread_ts']\n",
    "df_log_dm_ms = df_log_dm_ms.reindex(columns=reindex_col)\n",
    "df_log_dm_ms = df_log_dm_ms.reset_index().drop(columns='index')\n",
    "df_log_dm_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f6079-6236-448d-b891-72dd1395ce84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract value of files key\n",
    "files = []\n",
    "for i in df_log_dm_ms.index:\n",
    "    if 'files' in log_dm_ms[i].keys():\n",
    "        files.append(log_dm_ms[i]['files'][0])\n",
    "    else:\n",
    "        files.append({'name': 'None', 'url_private_download': 'None'})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105dea4-0df5-483a-a0b7-e8f2a88eb47d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create df of files and rename columns\n",
    "df_dm_files = pd.json_normalize(files)\n",
    "df_dm_files = df_dm_files[['name', 'url_private_download']]\n",
    "df_dm_files.rename(columns={'name': 'FileName', 'url_private_download': 'FileURL'}, inplace=True)\n",
    "df_dm_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa267f1c-8822-44fa-b9df-39a4ded096ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dm_log = pd.concat([df_log_dm_ms, df_dm_files], axis=1)\n",
    "\n",
    "# query('subtype != \"thread_broadcast\"') maybe unnecessary... because duplicates is dropped later \n",
    "# but prevent causing bugs by fixing it, I remain\n",
    "df_dm_log = df_dm_log.sort_values(by='ts').reset_index().drop('index',axis=1).query('subtype != \"thread_broadcast\"')\n",
    "df_dm_log_mi = df_dm_log.set_index(['type', 'thread_ts', 'ts'])\n",
    "df_dm_log_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04b075-2da3-48c9-8166-327dc0064f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get replies to associate with each replies by parent messages\n",
    "channel_id = dm['id']\n",
    "threads = []\n",
    "for i in df_dm_log.index:\n",
    "    # 要素がNaNじゃないことの判定\n",
    "    if np.isnan(df_dm_log['reply_count'][i]) == False:\n",
    "        thr = uclient.conversations_replies(channel=channel_id, ts=df_dm_log['thread_ts'][i])\n",
    "        thr_ms = thr.get('messages')\n",
    "        threads.append(thr_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729533f2-2166-4144-b8a1-d3f9c08801e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = []\n",
    "for i in range(len(threads)):\n",
    "    rep = threads[i]\n",
    "    for j in range(len(rep)):\n",
    "        #print(rep[i])\n",
    "        reps.append(rep[j])\n",
    "print(len(reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da1259-8d98-4c0c-9cc9-bc3cb84c8d5b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine messages (not included replies) with replies included parent messages\n",
    "if len(reps) != 0:\n",
    "    df_dm_rep = pd.json_normalize(reps)\n",
    "    df_dm_rep = df_dm_rep[['type', 'ts', 'user', 'text', 'reply_count', 'reply_users_count', 'thread_ts']]\n",
    "    df_dm_rep = df_dm_rep.sort_values('ts').reset_index().drop(columns='index')\n",
    "    df_dm_rep['type']='thread'\n",
    "    df_dm_rep_mi = df_dm_rep.set_index(['type', 'thread_ts', 'ts'])\n",
    "    df_dm_rep_mi\n",
    "    \n",
    "    df_dm_log = pd.concat([df_dm_log_mi, df_dm_rep_mi])\n",
    "\n",
    "    # remove duplicated parent messages by drop_duplicates\n",
    "    df_dm_log = df_dm_log.reset_index().drop_duplicates(subset = ['text', 'ts'], keep='last').reset_index().drop(columns='index')\n",
    "\n",
    "else:\n",
    "    df_dm_log = df_dm_log_mi.reset_index()\n",
    "\n",
    "df_dm_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f192bb-5048-4a9a-b9d1-67648ee290e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert dtypes of ts and thread_ts, from str to float, and replace NaN to 'None'\n",
    "df_dm_log_astype = df_dm_log.astype({'ts': float, 'thread_ts': float}).fillna('None')\n",
    "df_dm_log_astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc628d6e-3188-41d3-9166-b74fa9545ad5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace UNIX DATE to formatted one and separate ts to date and time (for multiindex)\n",
    "date = []\n",
    "time = []\n",
    "for i in range(len(df_dm_log_astype['ts'])):\n",
    "    if (type(df_dm_log_astype['ts'][i]) == np.float64 or \n",
    "        type(df_dm_log_astype['ts'][i]) == float):\n",
    "        # create list of date        \n",
    "        dt_raw = datetime.date.fromtimestamp(df_dm_log_astype['ts'][i])\n",
    "        dt = dt_raw.strftime('%a, %b %d, %Y')\n",
    "        date.append(dt)\n",
    "        print('finished formatting date')        \n",
    "        \n",
    "        # create list of time\n",
    "        ti_raw = datetime.datetime.fromtimestamp(df_dm_log_astype['ts'][i])\n",
    "        ti = ti_raw.strftime('%H:%M')\n",
    "        time.append(ti)       \n",
    "        print('finished formatting time') \n",
    "\n",
    "    # format thread_ts to datetime\n",
    "    if (type(df_dm_log_astype['thread_ts'][i]) == np.float64 or \n",
    "        type(df_dm_log_astype['thread_ts'][i]) == float):\n",
    "        dtime = datetime.datetime.fromtimestamp(df_dm_log_astype['thread_ts'][i])\n",
    "        df_dm_log_astype.iloc[i, 1] = dtime.strftime('%H:%M, %a, %b %d, %Y')\n",
    "        print ('finished formatting thread_datetime')\n",
    "    \n",
    "    else:\n",
    "        print('thread_ts is not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416aa7e-fbcd-4ee9-8e50-2b9d488732d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine formatted date and time to dataframe\n",
    "df_datetime = pd.DataFrame({'date': date, \n",
    "                            'time': time})\n",
    "df_dm_log_frt = pd.concat([df_datetime, df_dm_log_astype],axis=1).drop(columns='ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11dd60-3163-4a26-a851-8c25ed3e7ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace user id in names column to real_name\n",
    "for i in df_dm_log_frt.index:\n",
    "    #print(i)\n",
    "    for j in range(len(user_id_names)):\n",
    "        if df_dm_log_frt.user[i] == user_id_names[j][0]:\n",
    "            df_dm_log_frt.user[i] = user_id_names[j][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b203256-91ad-4dca-a917-830b8a77091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace user id in text column to real_name (maybe able to merge above cell?)\n",
    "for i in df_dm_log_frt.index:\n",
    "    for j in df_user_id_names.index:\n",
    "        if user_id_names[j][0] in df_dm_log_frt['text'][i]:\n",
    "            df_dm_log_frt['text'][i] = df_dm_log_frt['text'][i].replace(user_id_names[j][0], user_id_names[j][1])\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78bd740-9364-4da8-8305-78dc731105db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# format only uploading file (None of text fields)\n",
    "for i in df_dm_log_frt.index:\n",
    "    if df_dm_log_frt.text[i] == '':\n",
    "        df_dm_log_frt.text[i] = 'attached file(s) only'\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c9efa-e0c6-4eee-9c1b-3ea78d6cb8de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check result of formatting and replacing\n",
    "df_dm_log_frt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e4cea-34c4-464f-b7e8-391b1c480695",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multiIndex\n",
    "df_dm_log_frt_mi = df_dm_log_frt.set_index(['type', 'thread_ts', 'date', 'time'])\n",
    "df_dm_log_frt_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223eee0-134c-49d3-b211-9b24bee45538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_idx = 5\n",
    "my_name = 'hk'\n",
    "dm_user_name\n",
    "#= 'hk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890494f-b25a-4634-8bba-d27b7f12dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_date = datetime.date.today()\n",
    "backup_date = backup_date.strftime('%y%m%d')\n",
    "\n",
    "# DO NOT FORGET MODIFY YEAR (year of current backup workspace) \n",
    "tgt_ws_year = 2022\n",
    "print(backup_date)\n",
    "print(tgt_ws_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7f589-40e0-4b34-8b0e-332ba920d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_DM = '../DM/'\n",
    "if os.path.exists(path_DM) == False:\n",
    "    %mkdir path_DM\n",
    "else:\n",
    "    print('directory already exists')\n",
    "    \n",
    "path_DM_full = '../DM_full_log/'\n",
    "if os.path.exists(path_DM_full) == False:\n",
    "    %mkdir path_DM_full\n",
    "else:\n",
    "    print('directory already exists')\n",
    "    \n",
    "path_YEAR = str(tgt_ws_year)\n",
    "if os.path.exists(path_DM+path_YEAR) == False:\n",
    "    %mkdir path_DM+path_YEAR\n",
    "else:\n",
    "    print('directory already exists')\n",
    "\n",
    "if os.path.exists(path_DM_full+path_YEAR) == False:\n",
    "    %mkdir path_DM_full+path_YEAR\n",
    "else:\n",
    "    print('directory already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2dc8d-761e-40bc-ba51-823427dfa4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to export excel file (for remaining multiIndex and encoding automatically)\n",
    "df_dm_log_frt_mi.to_excel(path_DM+path_YEAR+'/DM_log_'+path_YEAR+'_'+my_name+'_'+dm_user_name+'_'+backup_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34577f-ccd8-44b1-aa2b-af4ea026db92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# recommend saving raw data (not included replies)\n",
    "with open(path_DM_full+path_YEAR+'/Raw_dm_log_NOrep'+path_YEAR+'_'+my_name+'_'+dm_user_name+'_'+backup_date+'_.dat', 'w') as f:\n",
    "    print(log_dm, file=f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54acb360-e604-46f8-b411-25674ca64f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replies raw data\n",
    "with open(path_DM_full+path_YEAR+'/Raw_dm_rep_log'+path_YEAR+'_'+my_name+'_'+dm_user_name+'_'+backup_date+'_.dat', 'w') as f:\n",
    "    print(thr, file=f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
